from sklearn.ensemble import RandomForestClassifier as RFC
import numpy as np

# select_feature
L, R = 0, 574

# trainX = np.load('d0_trX.npy')[:, L:R]
# trainY = np.load('d0_trY.npy')
# testX = np.load('d0_tsX.npy')[:, L:R]
# testY = np.load('d0_tsY.npy')


class RandomForestMalware(object):
    """Documentation for RandomForestMalware

    """
    TRAIN_FILE_X = 'd0_trX.npy'
    TRAIN_FILE_Y = 'd0_trY.npy'
    TEST_FILE_X = 'd0_tsX.npy'
    TEST_FILE_Y = 'd0_tsY.npy'

    def __init__(self):
        super(RandomForestMalware, self).__init__()
        self.rf = None

    def train(self, TRAIN_FILE_X, TRAIN_FILE_Y):
        self.train_x = np.load(TRAIN_FILE_X)[:, L:R]
        self.train_y = np.load(TRAIN_FILE_Y)
        self.rf = RFC(n_estimators=200, oob_score=True)
        self.rf.fit(self.train_x, self.train_y)

    def test(self, TEST_FILE_X, TEST_FILE_Y):
        self.test_x = np.load(TEST_FILE_X)[:, L:R]
        self.test_y = np.load(TEST_FILE_Y)
        rf_score = self.rf.score(self.test_x, self.test_y)
        print "rf_score: ", rf_score

    def predict(self, pre_x):
        return self.rf.predict(pre_x)


def confuion_matrix(pred, test):
    Tpos, Tneg, Fpos, Fneg = 0, 0, 0, 0
    # positive represent good app
    for i in range(pred.size):
        if pred[i] == 0:
            if test[i] == 0:
                Tpos += 1
            else:
                Fpos += 1
        else:
            if test[i] == 1:
                Tneg += 1
            else:
                Fneg += 1
    print "True positive", Tpos
    print "True negtive", Tneg
    print "False positive", Fpos
    print "False negtive", Fneg
    precision = Tpos*1.0/(Tpos+Fpos)
    recall = Tpos*1.0/(Tpos+Fneg)
    F1 = 2.0*precision*recall/(precision+recall)
    print "Precision:", precision
    print "Recall:", recall
    print "F1score:", F1
    return precision, recall, F1


def load_features(fname):
    f = open(fname)
    ret = []
    for line in f.readlines():
        ret.append(line.strip().split(' ')[0])
    return ret


def map_feature(ls):
    print "feature_num", len(ls)
    fmap = load_features('feature.csv')
    data = []
    for i, fim in enumerate(ls):
        if fim > 0.015:
            # L is PianYiLiang
            idx = i+L
            data.append((idx, fim, fmap[idx]))
    data.sort(key=lambda x: x[1], reverse=True)
    # print
    for x in data:
        print "id: %d FIm: %f Name: %s" % x


def print_feature_importance(fim):
    print "Feature Importance"
    map_feature(fim)


if __name__ == '__main__':

    # Load Data
    trainX = np.load('d0_trX.npy')[:, L:R]
    trainY = np.load('d0_trY.npy')
    testX = np.load('d0_tsX.npy')[:, L:R]
    testY = np.load('d0_tsY.npy')
    print trainY.shape
    print sum(trainY == 1)
    print testY.shape
    print sum(testY == 1)
    exit()

    ret = []

    for i in range(1):
        print "-----------------------------"
        print "TrainX:", trainX.shape
        # Run RandomForestClassifier
        rf = RFC(n_estimators=200, oob_score=True)
        # Training
        print "Training..."
        rf.fit(trainX, trainY)
        print "Traing Done!"
        print "Testing ... "
        print "Testing sample number:", testY.shape[0]
        sc = rf.score(testX, testY)
        print "Score:", sc
        predY = rf.predict(testX)
        # print sum(predY == testY)*1.0/testY.shape[0]
        print ""
        print_feature_importance(rf.feature_importances_)
        ret.append(confuion_matrix(predY, testY))
    sum = 0.0
    for i in ret:
        sum += i[2]
    print "Average:", sum/len(ret)
